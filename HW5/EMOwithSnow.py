# EMOwithSnow.pyï¼ˆå®¢æœå°è©±åˆ†æç‰ˆï¼‰

import os
import pandas as pd
import matplotlib
import matplotlib.pyplot as plt
import json
from snownlp import SnowNLP
import re
from collections import Counter

matplotlib.use('Agg')
matplotlib.rc('font', family='Microsoft JhengHei')

# ğŸ” ç¢ºä¿ static æ°¸é æŒ‡å‘ ./staticï¼ˆå°ˆæ¡ˆè³‡æ–™å¤¾ä¸‹ï¼‰
BASE_DIR = os.path.dirname(os.path.abspath(__file__))
output_dir = os.path.join(BASE_DIR, "static")
os.makedirs(output_dir, exist_ok=True)

# ğŸ” å®¢æœå°è©±åˆ†é¡é—œéµå­—
keyword_map = {
    "æŠ±æ€¨": ["ä¸å¥½", "å¤±æœ›", "ç”Ÿæ°£", "çˆ›", "å£æ‰", "å·®", "æŠ•è¨´", "æŠ±æ€¨", "ä¸æ»¿æ„"],
    "è©¢å•": ["è«‹å•", "æƒ³çŸ¥é“", "æ€éº¼", "å¯ä»¥å—", "å¦‚ä½•", "å•ä¸€ä¸‹", "ä»€éº¼æ™‚å€™"],
    "æ„Ÿè¬": ["è¬è¬", "æ„Ÿè¬", "è¾›è‹¦äº†", "è®š", "å¾ˆå¥½", "æ»¿æ„"],
    "å»ºè­°": ["å»ºè­°", "å¸Œæœ›", "è¦ºå¾—å¯ä»¥", "æ‡‰è©²", "å¦‚æœèƒ½", "ä¸‹æ¬¡å¯ä»¥"]
}

def classify_aspects(text):
    found = set()
    for aspect, keywords in keyword_map.items():
        for kw in keywords:
            if re.search(kw, text, flags=re.IGNORECASE):
                found.add(aspect)
    return list(found)

def generate_analysis(user_id, df):
    moodtrend_path = os.path.join(output_dir, f"moodtrend_{user_id}.png")
    aspect_bar_path = os.path.join(output_dir, f"aspect_bar_{user_id}.png")
    sequence_json_path = os.path.join(output_dir, f"aspect_sequence_{user_id}.json")

    # âœ… æ¸…æ´—è³‡æ–™
    df["text"] = df["text"].fillna("").astype(str)
    df = df[df["text"].str.len() > 2].reset_index(drop=True)

    if df.empty or "text" not in df.columns or "who" not in df.columns:
        raise ValueError("è³‡æ–™å…§å®¹ç‚ºç©ºï¼Œæˆ–ç¼ºå°‘ 'text' æˆ– 'who' æ¬„ä½ï¼Œè«‹ç¢ºèªæ ¼å¼ã€‚")

    # æƒ…ç·’åˆ†æèˆ‡åˆ†é¡
    df["sentiment"] = df["text"].apply(lambda x: SnowNLP(x).sentiments)
    df["aspects"] = df["text"].apply(classify_aspects)

    # ğŸ“ˆ ç•«æƒ…ç·’è®ŠåŒ–åœ–
    try:
        if not df["sentiment"].empty and df["sentiment"].nunique() > 1:
            plt.figure(figsize=(10, 4))
            plt.plot(df.index, df["sentiment"], marker="o")
            plt.title("å®¢æˆ¶æƒ…ç·’è®ŠåŒ–è¶¨å‹¢")
            plt.xlabel("å°è©±é †åº")
            plt.ylabel("æƒ…ç·’å€¼ (0=è² é¢, 1=æ­£é¢)")
            plt.tight_layout()
            plt.savefig(moodtrend_path)
            plt.close()
    except Exception as e:
        print(f"[âš ï¸ ç•«æƒ…ç·’åœ–å¤±æ•—] {e}")

    # ğŸ“Š ç•«å®¢æœå°è©±é¡å‹æ¯”ä¾‹åœ–
    all_aspects = [aspect for aspects in df["aspects"] for aspect in aspects]
    aspect_counts = Counter(all_aspects)

    try:
        if aspect_counts:
            plt.figure(figsize=(8, 5))
            plt.bar(aspect_counts.keys(), aspect_counts.values())
            plt.title("å®¢æœå°è©±é¡å‹åˆ†ä½ˆ")
            plt.ylabel("å‡ºç¾æ¬¡æ•¸")
            plt.xticks(rotation=30)
            plt.tight_layout()
            plt.savefig(aspect_bar_path)
            plt.close()
    except Exception as e:
        print(f"[âš ï¸ ç•«é¡å‹åœ–å¤±æ•—] {e}")

    # ğŸ“ æ¯ä½ä½¿ç”¨è€…å°è©±é¡å‹é †åº
    customer_sequences = {}
    for customer, group in df.groupby("who"):
        sequence = []
        prev = None
        for text in group["text"]:
            for aspect in classify_aspects(text):
                if aspect != prev:
                    sequence.append(aspect)
                    prev = aspect
        customer_sequences[customer] = sequence

    with open(sequence_json_path, "w", encoding="utf-8") as f:
        json.dump(customer_sequences, f, ensure_ascii=False, indent=2)

    # âœ… ç¢ºèªæª”æ¡ˆ
    print("ğŸ” å¯¦éš›å„²å­˜æª”æ¡ˆï¼š")
    print("æƒ…ç·’åœ–ï¼š", moodtrend_path, "âœ…" if os.path.exists(moodtrend_path) else "âŒ")
    print("é¡å‹åœ–ï¼š", aspect_bar_path, "âœ…" if os.path.exists(aspect_bar_path) else "âŒ")
    print("é¡å‹é †åº JSONï¼š", sequence_json_path, "âœ…" if os.path.exists(sequence_json_path) else "âŒ")

    return {
        "moodtrend_img": os.path.relpath(moodtrend_path, BASE_DIR),
        "aspect_bar_img": os.path.relpath(aspect_bar_path, BASE_DIR),
        "aspect_sequence_json": os.path.relpath(sequence_json_path, BASE_DIR)
    }
